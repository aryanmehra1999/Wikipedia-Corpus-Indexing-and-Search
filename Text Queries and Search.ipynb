{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval - Document Ranking and Search\n",
    "### Aryan Mehra  (2017A7PS0077P)  ||  Siddhant Khandelwal (2017A7PS0127P)\n",
    "\n",
    "### Text Queries and Search \n",
    "\n",
    "We first import the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import sys\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting appropriate options for display if need be - we would like to display full numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For printing the whole npy array\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell correction Heuristic\n",
    "This is the spell correction heuristic. We check if the word is misspelled and then replace it with the correct word before the actual search in the backend. The spell_correct function will return the spell corrected query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_correct(query):\n",
    "    print(\"Spell Check is activated ........ Running Spell Check\")\n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(query.split())\n",
    "    if misspelled:\n",
    "        for word in query.split():\n",
    "            if word in misspelled:\n",
    "                print(\"Correcting \" + word + \" to \" + spell.correction(word))\n",
    "                query = query.replace(word, spell.correction(word))\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple utility to stem the token in case we use the related word search heuristic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stemmed_token(token):\n",
    "    porter = nltk.PorterStemmer()\n",
    "    return porter.stem(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the query vector - Nearest word heuristic\n",
    "The following function ***process_query_vector*** takes as input the tokenized query vector, vocabulary words and their iverse word-to-index mapping, and the document frequency of every term in the corpus along with ***\"N\"*** - the number of documents itself. The ***Spell Correction (Bonus Heuristic)*** is also present inside this function which can be easily commented outto notice the difference that it will create to misspelled queries.\n",
    "\n",
    "***Steps -*** We first see whether the word is in the vocabulary or not. In case not, we give the user the option to replace the word with the highest occuring word of that \"non existant\" query term's stemmed equivalence class. We use the stemmed vocabulary metadata for the same. Hence, the ambiguity is resolved  in both single word and multi-term queries. We then proceed to do a ****LTC operation scheme*** on the query, using inverse document frequency and cosine normalization as well. Finally the processed query and vector is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_vector(query, vocabulary_keys, inverse_vocab_word_dict, term_document_frequency, N):\n",
    "    query_text = ''\n",
    "    for token in query:\n",
    "        query_text = query_text + ' ' + str(token)\n",
    "    query = query_text\n",
    "    query = query.lower()\n",
    "    \n",
    "    \n",
    "    print(\"Nearest word (Did you mean) heuristic is automatically activated ........... \")\n",
    "\n",
    "    # ----------------  BONUS HEURISTIC ------------------------\n",
    "    \n",
    "    query = spell_correct(query)\n",
    "    \n",
    "    # ----------------  BOUNUS HEURISTIC ------------------------\n",
    "\n",
    "    query_vector = np.zeros(len(vocabulary_keys))\n",
    "    query = nltk.word_tokenize(query)\n",
    "\n",
    "#     for one word queries we deal separately\n",
    "    if(len(query) == 1 and query[0] not in inverse_vocab_word_dict):\n",
    "        \n",
    "        print(query[0] + \" is not found in vocabulary. Using most appropriate substitution using root word analysis! \")\n",
    "        stemmed_token = get_stemmed_token(query[0])\n",
    "\n",
    "        # Now the query contains all tokens as it is, only the ones that do not excist\n",
    "        # in the vocabulary are replaced by their stemmed root versions\n",
    "        \n",
    "        stemmed_vocab = pickle.load(open(\"stemmed_vocab.pkl\", \"rb\"))\n",
    "        if(stemmed_token not in stemmed_vocab):\n",
    "            print(\"Sorry, Could not replace, no search results found, exiting the program by default\")\n",
    "            exit(0)\n",
    "        \n",
    "        fixed_token = stemmed_vocab[token][0]\n",
    "        print(\"Did you mean \" + fixed_token + \"? Press y for yes: \")\n",
    "        choice = input()\n",
    "        if choice != 'y':\n",
    "            print(\"Sorry, No search results found, exiting the program by default\")\n",
    "            exit(0)\n",
    "        \n",
    "        query[query.index(token)] = fixed_token\n",
    "        # Query has the wrong word replaced by the most common rooted word (with the same root as the wrong word)\n",
    "        print(\"Changed query: \" + ' '.join(query))\n",
    "        query_vector[inverse_vocab_word_dict[fixed_token]] = query_vector[inverse_vocab_word_dict[fixed_token]] + 1\n",
    "        \n",
    "        \n",
    "    elif(len(query) >= 1):\n",
    "        for token in query:\n",
    "            if(token not in inverse_vocab_word_dict):\n",
    "                print(token + \" not found in vocabulary.\")\n",
    "                stemmed_token = get_stemmed_token(token)\n",
    "                stemmed_vocab = pickle.load(open(\"stemmed_vocab.pkl\", \"rb\"))\n",
    "                if(stemmed_token not in stemmed_vocab):\n",
    "                    continue\n",
    "                fixed_token = stemmed_vocab[stemmed_token][0]\n",
    "                print(\"Did you mean \" + fixed_token + \"? Press y for yes: \")\n",
    "                choice = input()\n",
    "                if choice != 'y':\n",
    "                    print(\"Skipping \" + token)\n",
    "                    continue\n",
    "                query[query.index(token)] = fixed_token\n",
    "                print(\"Changed query: \" + ' '.join(query))\n",
    "                query_vector[inverse_vocab_word_dict[fixed_token]] = query_vector[inverse_vocab_word_dict[fixed_token]] + 1\n",
    "            else:\n",
    "                query_vector[inverse_vocab_word_dict[token]] = query_vector[inverse_vocab_word_dict[token]] + 1\n",
    "\n",
    "    # processing log calculations (L)\n",
    "    for i in range(query_vector.shape[0]):\n",
    "        if(query_vector[i] > 0):\n",
    "            query_vector[i] = 1 + math.log(query_vector[i])\n",
    "\n",
    "    # processing term normalization (T)\n",
    "    for i in range(query_vector.shape[0]):\n",
    "        if(query_vector[i] == 0):\n",
    "            continue\n",
    "        query_vector[i] = query_vector[i] * math.log(N/term_document_frequency[i])\n",
    "\n",
    "    # Cosine normalization (C)\n",
    "    temp_query_vector = np.copy(query_vector)\n",
    "    temp_query_vector = np.square(temp_query_vector)\n",
    "    temp_query_vector = np.sum(temp_query_vector)\n",
    "    temp_query_vector = np.sqrt(temp_query_vector)\n",
    "    query_vector = np.divide(query_vector, temp_query_vector)\n",
    "\n",
    "    return query, query_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score calculation with query vector and document vector\n",
    "This function is also quite self explanatory. We simply calculate the dot product of the vectors to give the scores of the query with all the documents in the corpus. We skip and comment out the division with vector magnitudes because due to the LTC and LNC scheme the magnitudes are anyway equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(query_vector, database_lnc):\n",
    "    scores = []\n",
    "    for id, document_vector in enumerate(database_lnc):\n",
    "        score = np.dot(query_vector, document_vector)\n",
    "        \n",
    "#         dinominator1 = np.linalg.norm(query_vector)\n",
    "#         dinominator2 = np.linalg.norm(document_vector)\n",
    "#         score = score/dinominator1\n",
    "#         score = score/dinominator2\n",
    "        \n",
    "        scores.append([id, score])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic for Title Weighting\n",
    "This function encodes the heuristic of title weighting. The score is increased for the documents whose title contains words from the query. It is assumed that such documents will be more important within the fetched documents and otherwise as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_weighting(scores, query, doc_titles):\n",
    "    title_weight = 0.1\n",
    "    trivial_words = [\"of\", \"and\", \"a\", \"the\", \"an\", \"is\"]\n",
    "    \n",
    "    print(\"Title weighting is activated ....... \")\n",
    "    \n",
    "    for doc_id, doc_title in enumerate(doc_titles):\n",
    "        doc_title_temp = doc_title.lower()\n",
    "        count = 0\n",
    "        for word in query:\n",
    "            if word in doc_title_temp:\n",
    "                if(word not in trivial_words):\n",
    "#                     print(\"The title weighted word is \" + word + \" for the title \" + doc_title)\n",
    "                    scores[doc_id][1] = scores[doc_id][1] + title_weight       \n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring function and Results Display\n",
    "This function has the main calls to the process_query_vector function and score calculation as well. The lines marked between comments can be used to activate and deactivate the title weight function as need be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(query, database_lnc, vocabulary_keys, inverse_vocab_word_dict, term_document_frequency, N, doc_titles):\n",
    "    corrected_query, query_vector = process_query_vector(query, vocabulary_keys, inverse_vocab_word_dict, term_document_frequency, N)\n",
    "    scores = calculate_score(query_vector, database_lnc)\n",
    "    \n",
    "#     #------------------- title weighting heuristic -----------------------\n",
    "\n",
    "    scores = title_weighting(scores, corrected_query , doc_titles)\n",
    "\n",
    "#     #------------------- title weighting heuristic -----------------------\n",
    "    \n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nTop Scoring Documents are: \")\n",
    "    for ind in range(10):\n",
    "        if(scores[ind][1] == 0):\n",
    "            break\n",
    "        print(doc_titles[scores[ind][0]] + \" is at rank \" +\n",
    "              str(ind+1) + \" Score: \" + str(scores[ind][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and populating appropriate data structures and metadata.\n",
    "We load the database that we had stored in the LNC scheme format in the index construction phase, along with the vocabulary dictionary. ***\"N\"*** represents the number of documents. Similarly other relevant structures are populated or loaded from metadata files. The ***inverse_vocab_word_dict*** is the inverse mapping of the word to it's index in thevocabulary for constant time access. One of the structures is also the ***term_document_frequency*** which is every vocabulary term's document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_lnc = np.load(\"database_lnc.npy\")\n",
    "N = database_lnc.shape[0]\n",
    "vocabulary_dict = pickle.load(open(\"vocabulary_dict.pkl\", \"rb\"))\n",
    "vocabulary_keys = list(vocabulary_dict.keys())\n",
    "inverse_vocab_word_dict = {k: v for v, k in enumerate(vocabulary_keys)}\n",
    "term_document_frequency = np.count_nonzero(database_lnc, axis=0)\n",
    "doc_titles = pickle.load(open(\"doc_titles.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating Sequence and Search Engine Interface Simulation\n",
    "After running this cell, we are good to go...!\n",
    "\n",
    "Sample inputs are mentioned in the report attached as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter the query to be searched: New York\n",
      "Nearest word (Did you mean) heuristic is automatically activated ........... \n",
      "Spell Check is activated ........ Running Spell Check\n",
      "Title weighting is activated ....... \n",
      "\n",
      "Top Scoring Documents are: \n",
      "\"Futurama (New York World's Fair)\" is at rank 1 Score: 0.29458171078747575\n",
      "\"Buffalo, New York\" is at rank 2 Score: 0.27738496007425395\n",
      "\"Bob Frankston\" is at rank 3 Score: 0.17549797644379897\n",
      "\"Big Apple\" is at rank 4 Score: 0.15692089291020234\n",
      "\"Brooklyn Historic Railway Association\" is at rank 5 Score: 0.11939342119534024\n",
      "\"Futurians\" is at rank 6 Score: 0.11439808034788743\n",
      "\"BBC News (TV channel)\" is at rank 7 Score: 0.11385650527130695\n",
      "\"Fiorello H. La Guardia\" is at rank 8 Score: 0.09432771509209387\n",
      "\"Fantasy Games Unlimited\" is at rank 9 Score: 0.0942019695489788\n",
      "\"William M. Tweed\" is at rank 10 Score: 0.09365293982216155\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Please Enter the query to be searched: \")\n",
    "query = query.split()\n",
    "scoring(query, database_lnc, vocabulary_keys, inverse_vocab_word_dict, term_document_frequency, N, doc_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
